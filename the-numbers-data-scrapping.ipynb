{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 2. Scrapping yearly market charts of top grossing movies\n",
    "This notebook will be used to scrap every year's movies top grossing movies (from 1995 to 2020).\n",
    "The website we use to get the data is https://www.the-numbers.com/\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os \n",
    "import re\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "from typing import List,Set,Dict"
   ]
  },
  {
   "source": [
    "## 2.1 Defining globals and functions\n",
    "We will use the following definitions: <br>\n",
    "- ``base_url: str`` - the base url of the website.\n",
    "- ``dir: str`` - the directory in which we save the html files.\n",
    "- ``years: List[int]`` - range of years we need to pull.\n",
    "- ``getYearUrl(year: str)-> str`` will return a url to fetch based on the given string.\n",
    "- ``getYearHTMLPath(year: str)-> str`` will return a local path to the html file of the given year.\n",
    "- ``createDirsRecursive(cur: str, next: list)`` will create directories recursively wether the sub directories exist or not."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url: str = \"https://www.the-numbers.com\"\n",
    "dir: str= os.path.join(\"src_data\",\"the-numbers-html\")\n",
    "years: List[int] = range(1995,2021)\n",
    "getYearURL: str = lambda year: f\"{base_url}/market/{year}/top-grossing-movies\"\n",
    "getYearHTMLPath: str = lambda year: os.path.join(dir,f\"{year}.html\")\n",
    "\n",
    "def createDirsRecursive(cur:str,next:List[str]):\n",
    "    if len(next) == 0 : return\n",
    "    a ,*b = next\n",
    "    cur = os.path.join(cur,a)\n",
    "    if not os.path.exists(cur):\n",
    "        os.mkdir(cur)\n",
    "    createDirsRecursive(cur,b)"
   ]
  },
  {
   "source": [
    "## 2.2 Downloading the data\n",
    "Here we create the sub directories needed and downloading the html files to use later instead of overheading network requests."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur,*next = os.path.split(dir)\r\n",
    "createDirsRecursive(cur,next)\r\n",
    "\r\n",
    "for year in years:\r\n",
    "    html = requests.get(getYearURL(year)).content\r\n",
    "    with open(getYearHTMLPath(year),\"wb\") as f:\r\n",
    "        f.write(html)\r\n",
    "        f.close()\r\n"
   ]
  },
  {
   "source": [
    "## 2.3 Creating soups and tables\n",
    "\n",
    "### First we will define some helper functions to compile a table from the html file.\n",
    "- ``convertStringToInt(string:str, sep:str, prefix: str)`` -  Will take a string seperate with ``sep`` value and trim the ``prefix`` provided and return the int value of it.\n",
    "- ``fixMovieName(name: str)`` -  Some movies contain special characters such as <b><u>’</u></b> as opposed to <b><u>'</u></b>. <br> \n",
    "Also some movies are trimmed so only the begging is present and the end is completed with <b><u>...</u></b> <br> \n",
    "To fix these problems we replace the <b><u>’</u></b> with <b><u>'</u></b> but we keep the <b><u>...</u></b> and then we will substring them.\n",
    "- ``createRow(...)`` - Will basically create a row tuple of the specific columns we need after parsing correctly and filling ``None``s where the data is missing\n",
    "- ``createTableFromSoup(soup: BeautifulSoup)`` - Will create a dataframe from a given HTML soup using the functions above"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This function will take a number represented in a string with special delimiters and prefixes.\n",
    "#It will simplify the string to a parsable integer and then return it as an int\n",
    "\n",
    "def convertStringToInt(string:str,sep:str,prefix:str= \"\"):\n",
    "\n",
    "\n",
    "    string = string.split(sep)\n",
    "    string[0] = string[0][len(prefix):]\n",
    "    return int(\"\".join(string))\n",
    "\n",
    "#This function will convert special non-standard characters to standard ones\n",
    "fixMovieName:str = lambda n: n.replace(\"’\",\"'\").replace(\"—\",\"-\")\n",
    "\n",
    "\n",
    "#This function will create a row in the final table\n",
    "def createRow(row,year):\n",
    "    rank,movie,date,dist,genre,gross,tickets = row\n",
    "    movie_name = fixMovieName(movie.text)\n",
    "    link = movie.a['href'].split(\"#\")[0]\n",
    "    id = hashlib.md5(movie.a[\"href\"].encode(\"utf-8\")).hexdigest()\n",
    "    try: dist = dist.text\n",
    "    except: dist = None\n",
    "\n",
    "    try: date = date.a['href'].split('daily/')[1]\n",
    "    except: date= None\n",
    "\n",
    "    try: gross = convertStringToInt(gross.text,\",\",\"$\",)\n",
    "    except: gross = None\n",
    "\n",
    "    try: tickets = convertStringToInt(tickets.text,\",\")\n",
    "    except: tickets = None\n",
    "    \n",
    "    return {\n",
    "        \"id\":id,\n",
    "        \"link\":link,\n",
    "        \"movie\":movie_name,\n",
    "        \"date\":date,\n",
    "        \"dist\":dist,\n",
    "        f\"gross_{year}\":gross,\n",
    "        f\"tickets_{year}\":tickets\n",
    "    }\n"
   ]
  },
  {
   "source": [
    "### Creating soup objects for each year\n",
    "We will iterate over the years and create soup objects for each year and store in a dict\n",
    "where the key is the year and the object is the soup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soups = {}\n",
    "for year in years:\n",
    "    with open(getYearHTMLPath(year),\"r\",encoding=\"utf-8\") as file:\n",
    "        soups[year]=BeautifulSoup(file.read(),'lxml')\n",
    "        file.close()\n"
   ]
  },
  {
   "source": [
    "### Creating a full dictionary of data\n",
    "We will create a dictionary where the keys are unique ids generated for each movie and the values will be a dict of the data on said movie\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dict={}\n",
    "\n",
    "def updateMoviesDictFromSoup(soup:BeautifulSoup,year:str):\n",
    "    table = soup.find(\"div\",{\"id\":\"main\"}).table\n",
    "    #first row is for the colunm names, the others are data\n",
    "    rows = table.find_all(\"tr\")[1:-2]\n",
    "    ####### cols = [\"movie\",\"release_date\",\"distributor\",\"gross\",\"tickets\"]\n",
    "    for row in rows:\n",
    "        row = createRow(row.find_all(\"td\"),year)\n",
    "        id = row.pop(\"id\")\n",
    "        if id in movies_dict: movies_dict[id] ={**movies_dict[id] ,**row}\n",
    "        else: movies_dict[id] = row\n"
   ]
  },
  {
   "source": [
    "### Creating a dataframe for the 'the-numbers' table\n",
    "We will create an empty dataframe where the columns are\n",
    "- ``id`` - unique MD5 hashed id generated with the href of each movie\n",
    "- ``movie`` - for movie name\n",
    "- ``date`` - for movie's release date\n",
    "- ``dist`` - for the production distributor\n",
    "- ``gross_{year}`` - a gross_{year} is for each year and will store how much the movie grossed (can be nullish)\n",
    "- ``tickets_{year}`` - a tickets_{year} is for each year and will store the amount of tickets sold (can be nullish)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will create a list of prefixes and year ie [\"gross_1995\",\"gross_1996\",...]\n",
    "def createYearPrefixes(prefix,years):\n",
    "    prefixes = []\n",
    "    for year in years:\n",
    "        prefixes.append(f\"{prefix}_{year}\")\n",
    "    return prefixes\n",
    "\n",
    "df_fields=[\"id\",\"movie\",\"link\",\"date\",\"dist\",*createYearPrefixes(\"gross\",years),*createYearPrefixes(\"tickets\",years)]\n",
    "\n",
    "the_numbers_df = pd.DataFrame(columns=df_fields)\n"
   ]
  },
  {
   "source": [
    "### Filling the dataframe and sorting by date\n",
    "To fill the dataframe we will iterate over the ids of all movies and create rows accordingly.<br>\n",
    "(NOTE: some values ,mostly gross and tickets, will be NaN)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year,soup in soups.items():\n",
    "    updateMoviesDictFromSoup(soup,year)\n",
    "\n",
    "for id,data in movies_dict.items():\n",
    "    row = pd.Series({\"id\":id,**data})\n",
    "    the_numbers_df=the_numbers_df.append(row,ignore_index=True)\n",
    "\n",
    "the_numbers_df = the_numbers_df.sort_values(\"date\")"
   ]
  },
  {
   "source": [
    "## Saving The Dataframe\n",
    "We will save the dataframe and on the next notebook we will compile a final data set with cross references from 'the-numbers' and IMDB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_numbers_df.to_csv(\"output_data/the_numbers.csv\")"
   ]
  }
 ]
}